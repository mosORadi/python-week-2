{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Galaxy Observations: Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week in the **Introduction to Python** series, Luke went into the general structure/idea of Python, including some syntax, basic I/O, structures, etc. \n",
    "\n",
    "This week, I want to build on that by trying to get everyone comfortable **hacking at packages/methods without much experience**. Although Python has an enormous number of packages available that can do a lot of high-level tasks, I want to focus this week on a few core packages: `matplotlib` (the default plotting utility), `numpy` (useful for fast operations with a lot of numbers), and `scipy` (useful for a lot of built-in methods).\n",
    "\n",
    "We will use these packages this week to do some basic science: simulating a galaxy observation. This will have two components: simulating a photometric observation (the intensity of light as a function of wavelength) and, if time permits, simulating a spectroscopic observation (the intensity of light as a function of position and wavelength)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only necessary if you're running Python 2.7 or lower\n",
    "from __future__ import print_function\n",
    "from __builtin__ import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, we need to initialize the environment. First, let's import `pyplot` from `matplotlib`, which we will use to plot things. Then, we can use one of the \"magic commands\" to enable *in-line plotting*, which ensures our plots will show up in our actual notebook (rather than externally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import plotting utility and define our naming alias\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot figures within the notebook rather than externally\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some quick plots to see how things look using some fake data. We will use `numpy` to help us with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly generate some data. We'll start with a \"grid\" of points $\\mathbf{x}$ and compute the corresponding output $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a relationship: y = ax + b\n",
    "a, b = 1., 0.  # the trailing decimal guarantees this is a \"float\" rather than \"int\"\n",
    "\n",
    "# initialize our data\n",
    "n = 1000  # number of data points\n",
    "x = np.linspace(0., 100., n)  # our grid of `n` data points from 0. to 100.\n",
    "y = a * x + b  # our output y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some noise to our results using `numpy`'s built-in `random` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add in noise drawn from a normal distribution\n",
    "ye = np.random.normal(loc=0., scale=5., size=n)  # jitter\n",
    "yobs = y + ye  # observed result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our results look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot our results\n",
    "plt.plot(x, yobs)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('A (Noisy) Line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the parameters above to get some more familiarity with plotting. If you have time, see if you can:\n",
    "- Change the original relationship to a quadratic one.\n",
    "- Change the type of random noise we are adding to the data.\n",
    "- Change the colors used for plotting.\n",
    "- Change the \"linestyle\" used for plotting from connected lines to unconnected dots.\n",
    "- Change the x and y limits in the plot.\n",
    "and any other changes you'd like to experiment with.\n",
    "\n",
    "Feel free to use any resources you want to figure this out. For immediate results, try the `help` function (shown below) or **Shift-Tab** within a function. Googling is also perfectly legit: pretty much everyone who codes has a lot of \"how to do X python\"-style searches in their search history (I know I do). There's also some official documentation [online](https://matplotlib.org/faq/usage_faq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(plt.plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I always find the default label and axes markers to be too small to easily read (especially when showing people plots). Luckily, it's pretty straightforward to change the plotting defaults for `matplotlib` to make things easier to read. We can override the defaults whenever we plot something (which we'll get to in a bit) or we can just update them all at once (as below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from matplotlib import rcParams\n",
    "\n",
    "# re-defining plotting defaults\n",
    "rcParams.update({'xtick.major.pad': '7.0'})\n",
    "rcParams.update({'xtick.major.size': '7.5'})\n",
    "rcParams.update({'xtick.major.width': '1.5'})\n",
    "rcParams.update({'xtick.minor.pad': '7.0'})\n",
    "rcParams.update({'xtick.minor.size': '3.5'})\n",
    "rcParams.update({'xtick.minor.width': '1.0'})\n",
    "rcParams.update({'ytick.major.pad': '7.0'})\n",
    "rcParams.update({'ytick.major.size': '7.5'})\n",
    "rcParams.update({'ytick.major.width': '1.5'})\n",
    "rcParams.update({'ytick.minor.pad': '7.0'})\n",
    "rcParams.update({'ytick.minor.size': '3.5'})\n",
    "rcParams.update({'ytick.minor.width': '1.0'})\n",
    "rcParams.update({'xtick.color': 'k'})\n",
    "rcParams.update({'ytick.color': 'k'})\n",
    "rcParams.update({'font.size': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of commands above probably didn't work on the first try. What gives? Looking at the error, it's telling us that the name `'rcParams'` is not defined in any capacity. This makes some sense: we never defined this variable anywhere. Try uncommenting the first line and see if it works a second time (hopefully it should)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-plot our results to see what updating our defaults has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot our results\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x, yobs)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x', fontsize=20, color='darkviolet')\n",
    "plt.ylabel('y', fontsize=40, color='red')\n",
    "plt.title('A (Noisy) Line with Larger Font', y=1.05, color='navy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've changed the defaults, we notice a number of issues with our plot to do with our font size. This is because all outputs from `pyplot` are intrinsically drawn on a `Figure` object. If one of these are not initialized explicitly at the beginning, a default one is created. With our new larger fonts, the default figure feels a little squished. \n",
    "\n",
    "Play around with changing the size of our figure using the commented line. Feel free to also mess around with the arguments passed to the axes labels and titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxies and Emission Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some familiarity with plotting, let's move on to a bit more of the science. In the `seds/` folder, there are a bunch of files containing galaxy **spectral energy distributions** (SEDs). Let's load in [UGCA 166](https://en.wikipedia.org/wiki/I_Zwicky_18), a nearby blue compact dwarf galaxy that's actively forming stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('seds/brown_UGCA_166_spec.dat')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we loaded in is a $N \\times 2$-dimensional **`numpy` array**, where the first column is the wavelength (measured in **Angstroms**, $10^{-10}$ meters) while the second column is the relative **flux density** (energy per time per area per wavelength, i.e. the relative **intensity** of the light at that particular wavelength).\n",
    "\n",
    "Arrays are fixed-size data structures in Python that allow you to quickly manipulate lots of numbers. We'll be exploiting them here and you'll definitely be using them if you code in Python more regularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way `data` is currently structured is a bit awkward: the relevant quantities are the columns here, which makes plotting a bit awkward. One possible way to get around this is to make some new variables by (1) iterating through the array (using an *implicit* `for` loop) or (2) **slicing** through the array. Both of these are deomnstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iteration through the array using an implicit for loop\n",
    "print('Wavelength:', np.array([d[0] for d in data]))\n",
    "\n",
    "# slice the array along the 0th entry in the 1st dimension (i.e. by column, not row)\n",
    "print('Wavelength:', data[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate plotting and later manipulation, let's redefine our data to instead be 2 $N$-dimensional arrays called `wave` and `fgal_wave`. There are a bunch of ways to do this besides the two shown above, but the most direct way is to use `numpy`'s built-in **array manipulation** functions.\n",
    "\n",
    "**Extra challenge: can you code up your own custom method to do this? How many lines of code does your method take compared with the one line implementations shown above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take the transpose of the array (N x M) -> (M x N)\n",
    "print(data.T)\n",
    "wave, fgal_wave = data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the data to see what our galaxy looks like. Build on the bare-bones example below using the skills you've learned to make a better-looking plot. (At the minimum, please label the axes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flux density (per wavelength) vs wavelength (angstroms) for UGCA 166\n",
    "#plt.plot(wave, fgal_wave)\n",
    "#plt.semilogx(wave, fgal_wave)\n",
    "#plt.semilogy(wave, fgal_wave)\n",
    "#plt.loglog(wave, fgal_wave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closely, we see that there are a number of very visible \"spikes\" on the plot. These are particular **emission lines** associated with atomic transitions. These specific **spectral features** are a direct result of the energetic photons emitted from all the new/young stars in the galaxy. Try and zoom in on the particular region on the plot where most of these are located. Can you identify any lines in particular based on [this list](http://classic.sdss.org/dr6/algorithms/linestable.html)? Some of the most common ones are also defined below.\n",
    "\n",
    "**Extra challenge: Overplot the line wavelengths on the galaxy spectrum using the `plt.vlines` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining some common emission lines\n",
    "ha = 6564.6 # H-alpha [A]\n",
    "n2 = 6549.86 # NII [A]\n",
    "o3_1 = 5008.240 # OIII doublet (1) [A]\n",
    "o3_2 = 4960.295 # OIII doublet (2) [A]\n",
    "hb = 4862.7 # H-beta [A]\n",
    "o2 = 3728.4 # approximate center of (blended) OII doublet [A]\n",
    "\n",
    "# consolidating results in an array (in order of decreasing wavelength)\n",
    "emlines = np.array([ha, n2, o3_1, o3_2, hb, o2])\n",
    "emline_names = np.array(['Ha', 'NII', 'OIII (1)', 'OIII (2)', 'Hb', 'OII (1,2)'])\n",
    "Nlines = len(emlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, feel free to load in a few different galaxy spectra from the `seds/` folder (the `brown_` ones are particularly nice examples) to see how different galaxy spectra look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Transmission Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting spectra of a galaxy is actually quite expensive and time-consuming. Instead, many large upcoming surveys such as [*Euclid*](https://www.euclid-ec.org/) will be **photometric** surveys. This just means that instead of observing galaxies as a *function of* wavelength, they simply count how many (relative) photons they receive in a specific wavelength interval. In other words, they take pictures of the sky in a particular wavelength range!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UGCA 166 is kinda bizarre within our local neighborhood, but is probably a good example of what galaxies are like at higher [redshifts](https://en.wikipedia.org/wiki/Redshift) (i.e. earlier times). We would like to simulate what our galaxy would look like in the photometric **filters** that will be part of the *Euclid* and [LSST](https://www.lsst.org/) surveys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to extract the relevant **filter transmission curves**, which tell us how much light is ultimately transmitted through the filter at a particular wavelength. I've stored these in the `filters/` folder, so we need to extract them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filt_path='./filters/' # file path for the filters folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous galaxy file was just a bunch of numbers, which we were able to load in using `np.loadtxt`. Our list of filters, however, is a bunch of names. This means we need to read in the file a bit differently. Let's do this line by line just to be very explicit about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize lists\n",
    "filt_names = []  # empty list\n",
    "filt_files = []  # empty list\n",
    "\n",
    "# read in our filter names and file paths line-by-line\n",
    "filt_list = open(filt_path+'Euclid.list') # open list of filter files for Euclid+LSST\n",
    "for line in filt_list:\n",
    "    l = line.strip()  # strip out the end-carriage '\\n' if present\n",
    "    ls = l.split()  # split the line into component strings\n",
    "    filt_names.append(ls[0]) # filter name\n",
    "    filt_files.append(ls[1]) # filter file\n",
    "filt_list.close()  # close file (**ALWAYS REMEMBER TO DO THIS**)\n",
    "Nfilt = len(filt_files)  # number of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the components above to get a sense of what we just did. What happens if you remove parts or don't close the file? What operations can you do with lists? How about with arrays? Some quick examples are below. We'll be coming back to some of these subtleties later, but please don't hesitate to ask if you have any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(filt_names, filt_names * 2)\n",
    "#print(emlines, emlines * 2)\n",
    "#print(filt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in our individual filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize our lists\n",
    "fw = []  # wavelengths \n",
    "fnu = []  # frequencies\n",
    "ft = []  # transmission\n",
    "c = 2.998e18  # speed of light [A/s]\n",
    "for filt in filt_files:\n",
    "    fpath = filt_path + filt  # append filter name to filter path\n",
    "    temp = np.loadtxt(fpath)  # load ASCII text file (wavelength, transmission)\n",
    "    fw.append(temp[:, 0])  # wavelength ('lambda') [A]\n",
    "    fnu.append(c / temp[:, 0])  # frequency ('nu') [Hz]\n",
    "    ft.append(temp[:, 1])  # transmission (fraction from 0. to 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting some of these below building off of the basic layout. The basic `Figure` setup has been initialized along with two possible color schemes and a bunch of keyword arguments to the methods. Try to play around with the styles to see how they change things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize figure\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "# define a sequence of colors\n",
    "#colors = ['blue', 'magenta', 'red', 'orange', 'brown',  # this works because python implicitly\n",
    "#          'green', 'teal', 'goldenrod', 'coral', 'black']  # continues bracketed statements\n",
    "\n",
    "# define our colormap (see: https://matplotlib.org/examples/color/colormaps_reference.html)\n",
    "color_scale = np.linspace(0, 1, Nfilt)\n",
    "colors = plt.get_cmap('viridis')(color_scale) # \n",
    "for i in range(Nfilt):\n",
    "    plt.plot(fw[i], ft[i], ls='-', lw=2, label=filt_names[i], color=colors[i])\n",
    "plt.ylim([0, 1.5])\n",
    "plt.legend(loc=1, ncol=5, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think is causing the different features in the $\\lbrace U, G, R, I, Z, Y \\rbrace$ transmission curves and the worse overall levels of transmission relative to the $\\lbrace VIS, Y_w, J_w, H_w \\rbrace$ curves? (Hint: it has something to do with one of the biggest differences between the LSST and *Euclid* surveys.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's take a second to examine how we've set up the for loop above in more detail above.\n",
    "- The `range` argument initializes an **iterator** that goes from [0, `Nfilt`), where \"[\" signals *inclusive* (including zero) and \")\" signals *exclusive* (up to but excluding `Nfilt`), respectively.\n",
    "- We then step through the iterator using `i`, which takes on values 0, 1, 2, ... up to but excluding `Nfilt`.\n",
    "- For each value of `i`, we plot the corresponding element of `fw`, `ft`, `filt_names`, and `colors`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do this is to step through all these values simultaneously. Python allows you to do this using the `zip` method, which iterates over all zipped quantities simultaneously. Using the example below, see if you can rewrite the `for` loop above to loop over all quantities (`fw`, `ft`, `filt_names`, and `colors`) simultaneously. Feel free to also play around with this formatting to get more comfortable with how `zip` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "for i, filt_x, filt_y in zip(range(Nfilt), fw, ft):\n",
    "    plt.plot(filt_x, filt_y, ls='-', lw=2, label=filt_names[i], color=colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, there's also no need for us to generate a counter using `range`. Python natively allows us to \"count\" within our loop using the `enumerate` function, which wraps whatever we're looping over. See if you can use the example below to re-write the `for` loop above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "for i, stuff in enumerate(zip(filt_names, colors)):\n",
    "    plt.plot(fw[i], ft[i], ls='-', lw=2, label=stuff[0], color=stuff[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to compute some basic properties of our set of filters. We'll start with the **effective wavelength**. This can be seen as the approximate \"mean\" wavelength of the filter, accounting for the differing transmission as a function of wavelength. Defining our wavelengths as $\\lambda$, our frequencies as $\\nu$, and our transmission at a particular frequency as $T_\\nu$, the \"standard\" defition for this effective wavelength $\\lambda_{\\textrm{eff}}$:\n",
    "\n",
    "$$ \\lambda_{\\textrm{eff}} = \\exp \\left[ \\frac{\\int T_\\nu \\, \\ln \\lambda \\, d(\\ln \\nu)}{\\int T_\\nu \\, d(\\ln \\nu)} \\right] \\quad . $$\n",
    "\n",
    "Although this definition might seem a bit weird, the basic idea is we want to compromise between averaging as a function of wavelength compared to as a function of frequency, which don't give the same result since $ \\lambda = c / \\nu \\propto \\nu^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can break down this computation into four steps:\n",
    "1. compute the integral in the denominator,\n",
    "2. compute the integral in the numerator,\n",
    "3. exponentiate their ratio, and\n",
    "4. iterate over all of our filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a bunch of [numerical integration packages](https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html) available as part of `scipy` for more general applications. There also is a basic numerical integration tool [`trapz`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.trapz.html) as part of `numpy`, which should suffice for our purposes here. An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# integrate our function from the beginning of the notebook\n",
    "plt.plot(x, y)  # plot our original function\n",
    "plt.fill_between(x, y, color='blue', alpha=0.3)  # fill between y and 0 over our x's\n",
    "y_area = np.trapz(y, x)  # numerically integrate our function\n",
    "\n",
    "print('Integral = {0}'.format(y_area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the example above, see if you can compute (1) the denominator, (2) numerator, and (3) effective wavelength for a particular filter in the style shown below. Then see if you can turn this into an array of effective wavelengths over all filters. I've included a one-statement solution below just so this isn't a \"make it or break it\" point, but try and come up with your own implementation for practice.\n",
    "\n",
    "(Hint: Note that `numpy` has convenient array functions such as `np.log`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# denominator\n",
    "denominator = np.trapz(T, ln(freq))\n",
    "\n",
    "# numerator\n",
    "numerator = np.trapz(T * ln(wave), ln(freq))\n",
    "\n",
    "# effective wavelength (Schneider et al. 1983; Fukugita et al. 1996)\n",
    "filt_cent = np.exp(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# array of effective wavelengths (compact solution)\n",
    "filt_cent = np.array([np.exp(np.trapz(ft[i] * np.log(fw[i]), np.log(fnu[i])) / \n",
    "                             np.trapz(ft[i], np.log(fnu[i])))\n",
    "                      for i in range(Nfilt)])\n",
    "\n",
    "print(filt_cent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Extra Challenge: Code up a simple numerical integration scheme by hand.**\n",
    "\n",
    "**Extra Extra Challenge: Use `scipy.integrate` to do the integral instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the effective wavelength, we also want some basic metric of how \"wide\" our filter is. There a lot of ways to define this, just as there are a lot of ways to define an \"effective\" wavelength. Here, we will use the 95% interval where most of the transmission is contained. In other words, our \"width\" will be determined by the wavelengths where there's a total of 2.5% transmission remaining on the left/right edges. This is computed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializes a Nfilt x 2 array of \"empty\" values\n",
    "filt_bounds = np.empty((Nfilt, 2))\n",
    "\n",
    "# fraction of total flux from filter (confidence interval)\n",
    "fbound = 0.95\n",
    "for i in range(Nfilt):\n",
    "    cdf = np.cumsum(ft[i])  # compute the cumulative sum over the transmission curve\n",
    "    cdf /= cdf[-1]  # normalize the transmission curve to sum to 1.\n",
    "    fremain = (1 - fbound) / 2.  # amount remaining (fraction) on either end\n",
    "    \n",
    "    # compute left bound\n",
    "    temp = np.abs(cdf - fremain)  # absolute value\n",
    "    idx_left = np.argmin(temp)  # find the **index** of the minimum position\n",
    "    \n",
    "    # compute right bound\n",
    "    temp = np.abs(cdf - (1. - fremain))  # absolute value\n",
    "    idx_right = np.argmin(temp)  # find the **index** of the minimum position\n",
    "    \n",
    "    # assign bounds to our \n",
    "    filt_bounds[i] = fw[i][idx_left], fw[i][idx_right]  # lower/upper bound [A]\n",
    "\n",
    "# compute the \"width\" as the difference between the upper and lower 95% bounds\n",
    "filt_width = filt_bounds[:,1] - filt_bounds[:,0] # filter width [A]\n",
    "\n",
    "print(filt_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spend some time breaking down the above snippet of code so that you can (ideally) explicitly summarize what exactly each line is doing and why. One way I like to make sense of unfamiliar code is by pulling it apart and plotting some of the intermediate results. An example of this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 3\n",
    "cdf = np.cumsum(ft[i])\n",
    "cdf /= cdf[-1]\n",
    "fremain = (1 - fbound) / 2.\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(fw[i], ft[i] / max(ft[i]), color='black')  # normalize to 1.\n",
    "plt.plot(fw[i], cdf, color='blue')  # normalize to 1.\n",
    "\n",
    "temp = np.abs(cdf - fremain)\n",
    "idx_left = np.argmin(temp)\n",
    "plt.plot(fw[i], temp, color='red', linestyle='--')  # function we will minimize\n",
    "plt.vlines(fw[i][idx_left], 0., 1., color='red')\n",
    "\n",
    "temp = np.abs(cdf - (1. - fremain))\n",
    "idx_right = np.argmin(temp)\n",
    "plt.plot(fw[i], temp, color='red', linestyle='--')  # function we will minimize\n",
    "plt.vlines(fw[i][idx_right], 0., 1., color='red')\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Fraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this type of thing works for you, great! If not, definitely try and find out what general practices/strategies are effective for you since you'll probably be doing a lot of this as you become more involved in coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information, we can now compute the average **photon energy** within each filter (i.e. the minimum unit/quantum of energy). One of the seminal findings of quantum mechanics (and the thing that got Einstein the nobel prize) was that photon energy is *quantized* according to the relation\n",
    "\n",
    "$$ E = h \\nu = h c / \\lambda  \\quad . $$\n",
    "\n",
    "Let's use this relation to compute the (average) energy of an individual photon in each of our filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 2.998e18  # speed of light [A/s]\n",
    "h = 6.6260755e-27  # Planck constant in erg*s\n",
    "ephot_cent = h * c / filt_cent # photon energies at effective wavelength [erg]\n",
    "print(ephot_cent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all these bits and pieces, see if you can plot the average photon energy in each filter as a function of wavelength. A short example is shown below using `plt.errorbar` along with a short printout summary that utilizes the `round` function, but you're welcome to be as creative as you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "xlow, xhigh = filt_bounds.T\n",
    "xe_low, xe_high = filt_cent - xlow, xhigh - filt_cent\n",
    "plt.errorbar(filt_cent, ephot_cent, xerr=[xe_low, xe_high], linestyle='none', marker='o')\n",
    "\n",
    "# printout\n",
    "print('Filter', 'Center[A]', 'Width({0})[A]'.format(fbound), 'Low[A]', 'High[A]', 'E_phot[1e-12 erg]')\n",
    "for i in xrange(Nfilt):\n",
    "    print(filt_names[i], round(filt_cent[i], 1), filt_width[i], filt_bounds[i][0], \n",
    "          filt_bounds[i][1], round(ephot_cent[i] * 1e12, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Challenge: Can you get the axes of the plot to be (semi-)logarithmic rather than linear?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing a Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to simulate a basic observation of our original galaxy through our set of filters. First, we need to integrate our galaxy spectrum $S_\\nu$ over each filter. This takes a similar form to our calculation of the effective wavelength:\n",
    "\n",
    "$$ F_\\nu = \\frac{\\int T_\\nu \\, S_\\nu \\, d(\\ln \\nu)}{\\int T_\\nu \\, d(\\ln \\nu)} $$\n",
    "\n",
    "where $S_\\nu$ (flux density per *frequency*) and $S_\\lambda$ (flux density per *wavelength*) are related via\n",
    "\n",
    "$$ S_\\nu = S_\\lambda \\frac{\\lambda^2}{c}  $$ \n",
    "\n",
    "using the nifty result\n",
    "\n",
    "$$ d\\nu = d \\left(\\frac{c}{\\lambda}\\right) = - \\frac{c}{\\lambda^2} d\\lambda \\quad . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute S_\\nu\n",
    "fgal_nu = fgal_wave * wave**2 / c  # this works because units are [A] and [A/s]\n",
    "\n",
    "# plot our result\n",
    "plt.loglog(wave, fgal_nu)\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel(r'$S_\\nu$')  # LaTeX-style math; the preceding 'r' \"protects\" the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why this conversion between $S_\\nu$ and $S_\\lambda$? A mix between historical reasons and plotting usefulness (sometimes it's easier to visualize trends as per unit wavelength instead of per unit frequency, and vice versa). Plotting things in $S_\\nu$ tends to highlight behavior in the optical range (which becomes \"flatter\" the more star formation a galaxy tends to have)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using everything we've covered up to this point, we're now ready to simulate our galaxy observation. First, let's integrate our galaxy over the filters to get the relative photometric flux density $F_\\nu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = c / wave\n",
    "phot = np.array([np.trapz(ft[i] * fgal_nu, np.log(freq)) / \n",
    "                 np.trapz(ft[i], np.log(freq))\n",
    "                 for i in range(Nfilt)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no -- it seems we've hit an error! It turns out our galaxy is observed at a different number of wavelengths compared to our original filter. To integrate numerically, we need both our filter and the galaxy spectrum to be observed at the exact same wavelength values. This requires us to **interpolate** one of our values. Since the galaxy wavelength grid appears to be more precise, let's go with interpolating all of our filter results onto a galaxy grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation in Python is super easy using functions like `np.interp`. See if you can interpolate the transmission from filter onto the wavelength grid spanned by our galaxy (`wave`), under the condition that values outside the boundaries of the filter are automatically set to zero. An incomplete solution is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interpolation (incomplete)\n",
    "np.interp(wave, fw[i], ft[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, let's redo our integral from above. I've provided a one-statement solution below, but I would highly encourage everyone to try their hand at implementing something themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute relative photometry\n",
    "phot = np.array([np.trapz(np.interp(wave, fw[i], ft[i], left=0., right=0.) * fgal_nu, np.log(freq)) / \n",
    "                 np.trapz(np.interp(wave, fw[i], ft[i], left=0., right=0.), np.log(freq))\n",
    "                 for i in range(Nfilt)])\n",
    "\n",
    "print(phot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this result is unnormalized because we haven't compared this *relative* result to some standard value. To correct for this and make the final answer more realistic, we're just going to multiply this result by $10^{-23}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phot *= 1e-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to derive error bars on our photometry. Let's pretend for a (beautiful) second that there is no other source of noise other than the source itself (i.e. ignoring the sky, instrument, etc., and only counting the number of photons received from our observed galaxy). The uncertainty on our photometry is directly related to the uncertainty in the number of photons we expect to receive. This is an example of a [Poisson process](https://en.wikipedia.org/wiki/Poisson_point_process), and it turns out the standard deviation in the number of photons we receive is just\n",
    "\n",
    "$$ \\sigma_N = \\sqrt{N} ~\\Rightarrow~ \\sigma_N / N = 1/\\sqrt{N} \\quad . $$\n",
    "\n",
    "So our fractional uncertainty is just $1/\\sqrt{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the photon energies we computed earlier, compute the fractional uncertainties we expect in each filter assuming a 4hr observation with a 8m telescope at the effective wavelength of each filter.** Remember that our photometric flux densities have units of erg/s/cm$^2$/Hz. Again, I've added in a one-statement solution so you can continue on, but please try and write your own code to compute this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phot_ferr = np.empty(Nfilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phot_ferr = 1. / np.sqrt(phot * (c / filt_cent) * (8. * 100. * 100.) * (4. * 60. * 60.) / ephot_cent)\n",
    "print(phot_ferr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot everything together: the galaxy SED, the expected photometry, and the observed filter set. A bare-bones example is shown below, where I've input lots of values by hand using trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot our results\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(wave, fgal_nu / np.median(fgal_nu) * 0.8, color='red', alpha=0.4)\n",
    "for i in range(Nfilt):\n",
    "    plt.plot(fw[i], ft[i], ls='-', lw=2, color='blue')\n",
    "plt.xlim([2e3, 2e4])\n",
    "plt.ylim([0, 1.5])\n",
    "plt.errorbar(filt_cent, phot / max(phot) * 1.2, xerr=[xe_low, xe_high],\n",
    "             yerr = phot * phot_ferr / max(phot) * 1.2,\n",
    "             marker='o', markersize=10, linestyle='none', color='red')\n",
    "plt.xlabel('Wavelength [A]')\n",
    "plt.ylabel('Flux Density [per Hz]', fontsize=26)\n",
    "plt.title('UGCA 166 Photometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Challenge: Can you add in some Gaussian (i.e. Normal) white noise to the observation to better mimic an observed *realization* of our galaxy?**\n",
    "\n",
    "**Extra Challenge: Assume that random sky noise creates 2 photons per hour per (projected) m$^2$. How does this change the noise calculations above?**\n",
    "\n",
    "**Extra Extra Challenge: Our noise assumptions above assume that we can approximate a discrete counting process (Poisson) using a continuous function (Normal). This can lead to problems since we only observe a discrete number of photons and we can't observe negative photons. Simulate the actual expected photon counts from a Poisson distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's that!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
